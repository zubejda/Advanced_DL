{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubejda/Advanced_DL/blob/main/minimal_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEeijgyYlvE7"
      },
      "source": [
        "![alternatvie text](https://www.doc.zuv.fau.de//M/FAU-Logo/01_FAU_Kernmarke/Web/FAU_Kernmarke_Q_RGB_blue.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKwgdqUglvE_"
      },
      "source": [
        "# Assignment 3: Minimal GAN in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S14tXjilvFA"
      },
      "source": [
        "Generative adversarial network (GAN) are well-known deep generative models proposed by [Ian Goodfellow](https://www.iangoodfellow.com) that could be used for synthesising data. It consists of two components, a generator (G) network that learns the data distribution and generates new examples and a discriminator (D) network that distinguishes between real and fake examples i.e. examples generated by G. In this assignment, you'll be asked to implement a series of tasks related to GANs using MNIST and Fashion-MNIST datasets. You upload your use a local python editor or python notebook e.g. Jupyter to implement your solution.\n",
        "\n",
        "Prior to the assignment, it is necessary to install a package manager e.g. [conda](https://docs.conda.io/en/latest/), and [PyTorch](https://pytorch.org) framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_tica2ulvFB"
      },
      "source": [
        "## 1. Implement GAN in PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uR6GEDllvFC"
      },
      "source": [
        "This public github [repository](https://github.com/bazilas/minimal-gan) implements GANs using tensorflow framework to reconstruct samples from MNIST and Fashion-MNIST data The first task is to re-implement the code (gan.py) using PyTorch framework instead. You should report your training performance i.e. train loss as a figure and another figure containing a batch of generated images after training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FsiUoFDElvFD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_9PkixorlvFE"
      },
      "outputs": [],
      "source": [
        "##load  MNIST\n",
        "\n",
        "fashion_mnist = False\n",
        "\n",
        "if fashion_mnist == False:\n",
        "    dataset = datasets.MNIST('MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n",
        "else:\n",
        "    dataset = datasets.FashionMNIST('Fashion-MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=100, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o05bolljlvFF"
      },
      "outputs": [],
      "source": [
        "#setup generator\n",
        "zdim = 50\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(zdim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kxazaAUMlvFF"
      },
      "outputs": [],
      "source": [
        "#setup discriminator\n",
        "xdim = 784\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(xdim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "        )\n",
        "        self.prob = nn.Sigmoid()\n",
        "    def forward(self, input):\n",
        "        x = self.main(input)\n",
        "        return self.prob(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample\n",
        "def draw_sample(m, n):\n",
        "    return numpy.random.uniform(-1.0, 1.0, size=[m, n])"
      ],
      "metadata": {
        "id": "xscJw_OubF2J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulIqX_PflvFF"
      },
      "outputs": [],
      "source": [
        "#training loop\n",
        "x = torch.tensor(draw_sample(1, 784), dtype=torch.float32)\n",
        "z = torch.tensor(draw_sample(1, zdim), dtype=torch.float32)\n",
        "\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "\n",
        "opt_g = optim.Adam(G.parameters(), lr=0.0002)\n",
        "opt_d = optim.Adam(D.parameters(), lr=0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbafGauylvFG"
      },
      "outputs": [],
      "source": [
        "#plot losses and generated images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIgCE4Y5lvFG"
      },
      "source": [
        "## 2a. Implement GAN with Convolutional architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSHWiNGVlvFG"
      },
      "source": [
        "Convolurional neural networks (CNNs) have a better feature representation, unlike, fully connected layers. Hence, it is required here to modify your code to include CNNs in your script. For more information, check out this [tutorial](https://gucifer.github.io/mediator/feature/2021/08/11/GAN-evaluation-using-FID-and-IS.html).\n",
        "\n",
        "Similar to before, please report your training performance i.e. train loss as a figure and another figure containing a batch of generated images after training. You can plot one figure including and highlight the train loss using fully connected and CNN networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqFLkGjOlvFH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLlKjWnHlvFH"
      },
      "outputs": [],
      "source": [
        "#load MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S3Y5erqlvFI"
      },
      "outputs": [],
      "source": [
        "#setup convolutional generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2tR7uMglvFI"
      },
      "outputs": [],
      "source": [
        "#etup convolutional discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIkhQi8FlvFI"
      },
      "outputs": [],
      "source": [
        "#training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b80phoMlvFI"
      },
      "outputs": [],
      "source": [
        "#plot losses and generated images with the convolutional GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPQ6rbv3lvFJ"
      },
      "source": [
        "## 2b. now reimplement this with FASHION-MNIST with a convolutinal architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iKIHCMJlvFJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_7esjHhlvFJ"
      },
      "source": [
        "## 3. Conditional GAN (cGAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijgYYRhJlvFJ"
      },
      "source": [
        "Vanilla GANs produce synthetic images by drawing a random vector from latent space. However, we may condition the GAN to additional information, namely, a class label e.g. label  \"0\" in MNIST. This requires to additionally input the label to G and D networks along with random vector drawn from latent space. You may use this [cGAN](https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/) tutorial to implement a cGAN based on the convolutional archiecture you've implemented before. Furthermore, MNIST should be used in this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XDWRaCglvFJ"
      },
      "outputs": [],
      "source": [
        "#generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKCnYTQYlvFJ"
      },
      "outputs": [],
      "source": [
        "#define training step for generator\n",
        "\n",
        "#define training step for discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJlb9UoWlvFK"
      },
      "outputs": [],
      "source": [
        "#training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whJJlqp6lvFK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k14z6nxlvFK"
      },
      "outputs": [],
      "source": [
        "#plot looses and generated images along wth their conditions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}