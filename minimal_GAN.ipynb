{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubejda/Advanced_DL/blob/main/minimal_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEeijgyYlvE7"
      },
      "source": [
        "![alternatvie text](https://www.doc.zuv.fau.de//M/FAU-Logo/01_FAU_Kernmarke/Web/FAU_Kernmarke_Q_RGB_blue.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKwgdqUglvE_"
      },
      "source": [
        "# Assignment 3: Minimal GAN in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S14tXjilvFA"
      },
      "source": [
        "Generative adversarial network (GAN) are well-known deep generative models proposed by [Ian Goodfellow](https://www.iangoodfellow.com) that could be used for synthesising data. It consists of two components, a generator (G) network that learns the data distribution and generates new examples and a discriminator (D) network that distinguishes between real and fake examples i.e. examples generated by G. In this assignment, you'll be asked to implement a series of tasks related to GANs using MNIST and Fashion-MNIST datasets. You upload your use a local python editor or python notebook e.g. Jupyter to implement your solution.\n",
        "\n",
        "Prior to the assignment, it is necessary to install a package manager e.g. [conda](https://docs.conda.io/en/latest/), and [PyTorch](https://pytorch.org) framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_tica2ulvFB"
      },
      "source": [
        "## 1. Implement GAN in PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uR6GEDllvFC"
      },
      "source": [
        "This public github [repository](https://github.com/bazilas/minimal-gan) implements GANs using tensorflow framework to reconstruct samples from MNIST and Fashion-MNIST data The first task is to re-implement the code (gan.py) using PyTorch framework instead. You should report your training performance i.e. train loss as a figure and another figure containing a batch of generated images after training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "deMi1bvpX8VE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FsiUoFDElvFD"
      },
      "outputs": [],
      "source": [
        "import comet_ml\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass('Enter your Comet API key: ')\n",
        "\n",
        "os.environ['COMET_API_KEY'] = api_key\n",
        "\n",
        "# Retrieve the API key from the environment variable\n",
        "COMET_API_KEY = os.getenv('COMET_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFfiYb0EX3Mo",
        "outputId": "55cf76ea-ea6d-4e87-95e8-f319825845cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Comet API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o05bolljlvFF"
      },
      "outputs": [],
      "source": [
        "#setup generator\n",
        "zdim = 50\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(zdim, 128),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(64, 128),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(128, 256),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(128, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxazaAUMlvFF"
      },
      "outputs": [],
      "source": [
        "#setup discriminator\n",
        "xdim = 784\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(xdim, 128),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.ReLU(),\n",
        "            # # nn.Linear(256, 128),\n",
        "            # nn.Dropout(p=0.1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "        )\n",
        "        self.prob = nn.Sigmoid()\n",
        "    def forward(self, input):\n",
        "        x = self.main(input)\n",
        "        return x, self.prob(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of trainable parameters\n",
        "gen = Generator()\n",
        "disc = Discriminator()\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(gen)\n",
        "print(f\"Total trainable (generator) parameters: {total_params}\")\n",
        "total_params = count_parameters(disc)\n",
        "print(f\"Total trainable (discriminator) parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPOAsBS5zMwV",
        "outputId": "6c6a138d-ba37-45fc-f15d-5f86b221dbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable (generator) parameters: 107664\n",
            "Total trainable (discriminator) parameters: 100609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample\n",
        "def draw_sample(m, n):\n",
        "    return np.random.uniform(-1.0, 1.0, size=[m, n]).astype(np.float32)"
      ],
      "metadata": {
        "id": "xscJw_OubF2J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_n_samples(data_loader, n):\n",
        "    samples = []\n",
        "    data_iter = iter(data_loader)\n",
        "\n",
        "    while len(samples) < n:\n",
        "        try:\n",
        "            imgs, _ = next(data_iter)\n",
        "            samples.append(imgs)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(data_loader)\n",
        "\n",
        "    samples = torch.cat(samples)[:n]\n",
        "    return samples"
      ],
      "metadata": {
        "id": "Iev1MwrA85Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_9PkixorlvFE",
        "collapsed": true,
        "outputId": "fbc8c3ea-e566-413e-bedc-4962d4a5aa19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 51606778.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 2318120.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 11673474.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1933278.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "##load  MNIST\n",
        "\n",
        "params = dict(\n",
        "  num_epochs = 200,\n",
        "  batch_size = 64,\n",
        "  learning_rate = 0.0002,\n",
        "  momentum=1e-4,\n",
        "  fashion_mnist = False\n",
        ")\n",
        "\n",
        "if params['fashion_mnist'] == False:\n",
        "    dataset = datasets.MNIST('MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n",
        "else:\n",
        "    dataset = datasets.FashionMNIST('Fashion-MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a Comet experiment to track our training run ###\n",
        "\n",
        "def create_experiment():\n",
        "  # end any prior experiments\n",
        "  if 'experiment' in locals():\n",
        "    experiment.end()\n",
        "\n",
        "  # initiate the comet experiment for tracking\n",
        "  experiment = comet_ml.Experiment(\n",
        "                  api_key=COMET_API_KEY,\n",
        "                  project_name=\"ADL_GAN1\",)\n",
        "  # log our hyperparameters, defined above, to the experiment\n",
        "  for param, value in params.items():\n",
        "    experiment.log_parameter(param, value)\n",
        "  experiment.flush()\n",
        "\n",
        "  return experiment"
      ],
      "metadata": {
        "id": "lWORJwPnYs8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulIqX_PflvFF"
      },
      "outputs": [],
      "source": [
        "#training loop\n",
        "x = torch.tensor(draw_sample(1, 784), dtype=torch.float32).to(device)\n",
        "z = torch.tensor(draw_sample(1, zdim), dtype=torch.float32).to(device)\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "G_sample_train = G(z)\n",
        "D_logit_real, D_real = D(x)\n",
        "D_logit_gen, D_fake = D(G_sample_train.detach())\n",
        "G_sample_inf = G(z)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "D_loss_real = criterion(D_logit_real, torch.ones_like(D_logit_real))\n",
        "D_loss_gen = criterion(D_logit_gen, torch.zeros_like(D_logit_gen))\n",
        "D_loss = D_loss_real + D_loss_gen\n",
        "\n",
        "G_loss = criterion(D_logit_gen, torch.ones_like(D_logit_gen))\n",
        "\n",
        "opt_g = optim.Adam(G.parameters(), lr=0.0002, betas=(0.8, 0.999))\n",
        "opt_d = optim.Adam(D.parameters(), lr=0.0001, betas=(0.9, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_samples = get_n_samples(data_loader, 9)\n",
        "experiment = create_experiment()\n",
        "\n",
        "for epoch in range(params['num_epochs']):\n",
        "    for batch_idx, (real_imgs, _) in enumerate(data_loader):\n",
        "        # Update discriminator\n",
        "        real_imgs = real_imgs.view(-1, 784).to(device)\n",
        "        z = torch.tensor(draw_sample(params['batch_size'], zdim)).to(device)\n",
        "\n",
        "        opt_d.zero_grad()\n",
        "\n",
        "        G_sample_train = G(z)\n",
        "        D_logit_real, D_real = D(real_imgs)\n",
        "        D_logit_gen, D_fake = D(G_sample_train.detach())\n",
        "\n",
        "        D_loss_real = criterion(D_logit_real, torch.ones_like(D_logit_real))\n",
        "        D_loss_gen = criterion(D_logit_gen, torch.zeros_like(D_logit_gen))\n",
        "        D_loss = D_loss_real + D_loss_gen\n",
        "\n",
        "        D_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(D.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        opt_d.step()\n",
        "\n",
        "        # Update generator\n",
        "        # z = torch.tensor(draw_sample(params['batch_size'], zdim)).to(device)\n",
        "        opt_g.zero_grad()\n",
        "\n",
        "        # G_sample_train = G(z)\n",
        "        D_logit_gen, D_fake = D(G_sample_train)\n",
        "\n",
        "        G_loss = criterion(D_logit_gen, torch.ones_like(D_logit_gen))\n",
        "\n",
        "        G_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(G.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        opt_g.step()\n",
        "\n",
        "    # if epoch % 20 == 0:\n",
        "    print(f'Epoch [{epoch}/{params[\"num_epochs\"]}], D_loss: {D_loss.item():.4f}, G_loss: {G_loss.item():.4f}, D_loss_real: {D_loss_real.item():.4f}, D_loss_gen: {D_loss_gen.item():.4f}, Total loss: {G_loss.item() + D_loss.item():.4f}, ratio: {G_loss.item() / D_loss.item():.4f}')\n",
        "\n",
        "    if epoch % 20 == 0 or G_loss.item() < 1.75:\n",
        "        noise = torch.tensor(draw_sample(100, zdim)).to(device)\n",
        "        samples = G(noise)\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        gs = gridspec.GridSpec(10, 10)\n",
        "        for j, sample in enumerate(samples):\n",
        "            sample = sample.detach().cpu().numpy()\n",
        "            ax = plt.subplot(gs[j])\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        path = '/content/res'\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        plt.savefig('/content/res/{}.png'.format(str(epoch).zfill(4)), bbox_inches='tight')\n",
        "        plt.close()\n",
        "        if epoch % 20 != 0:\n",
        "            models_path = '/content/models/'\n",
        "            if not os.path.exists(models_path):\n",
        "                os.makedirs(models_path)\n",
        "            torch.save(G.state_dict(), models_path + 'generator'+str(epoch)+'.pth')\n",
        "            torch.save(D.state_dict(), models_path + 'discriminator'+str(epoch)+'.pth')\n",
        "\n",
        "    experiment.log_metric(\"generator_loss\", G_loss, step=epoch)\n",
        "    experiment.log_metric(\"discriminator_loss\", D_loss, step=epoch)\n",
        "\n",
        "experiment.flush()"
      ],
      "metadata": {
        "id": "kV_bPKFHv9dJ",
        "outputId": "e898c814-cfbb-4c9c-ae03-1ccb888f8ffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : cool_tilapia_295\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/zubejda/adl-gan1/27392ee2e2bb4ec1941e05fcdca9528e\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     discriminator_loss [58] : (0.42475301027297974, 0.9730280637741089)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     generator_loss [58]     : (1.2291193008422852, 2.5094547271728516)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [11068]            : (0.264310359954834, 2.646353244781494)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fashion_mnist : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate : 0.0002\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum      : 0.0001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_epochs    : 200\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/zubejda/adl-gan1/8f2ce651abd54358816ddfd9cb29fac4\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 19 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/200], D_loss: 0.4702, G_loss: 1.7557, D_loss_real: 0.2622, D_loss_gen: 0.2080, Total loss: 2.2259, ratio: 3.7338\n",
            "Epoch [1/200], D_loss: 0.8424, G_loss: 0.7611, D_loss_real: 0.1812, D_loss_gen: 0.6613, Total loss: 1.6035, ratio: 0.9034\n",
            "Epoch [2/200], D_loss: 0.7995, G_loss: 0.8767, D_loss_real: 0.2002, D_loss_gen: 0.5993, Total loss: 1.6763, ratio: 1.0965\n",
            "Epoch [3/200], D_loss: 0.3322, G_loss: 1.9963, D_loss_real: 0.1300, D_loss_gen: 0.2021, Total loss: 2.3285, ratio: 6.0101\n",
            "Epoch [4/200], D_loss: 0.6609, G_loss: 1.3291, D_loss_real: 0.2661, D_loss_gen: 0.3948, Total loss: 1.9899, ratio: 2.0111\n",
            "Epoch [5/200], D_loss: 0.9885, G_loss: 1.4117, D_loss_real: 0.5590, D_loss_gen: 0.4295, Total loss: 2.4001, ratio: 1.4281\n",
            "Epoch [6/200], D_loss: 0.6667, G_loss: 1.4338, D_loss_real: 0.3257, D_loss_gen: 0.3409, Total loss: 2.1005, ratio: 2.1508\n",
            "Epoch [7/200], D_loss: 0.4644, G_loss: 1.7177, D_loss_real: 0.1970, D_loss_gen: 0.2674, Total loss: 2.1822, ratio: 3.6986\n",
            "Epoch [8/200], D_loss: 0.8040, G_loss: 1.5723, D_loss_real: 0.4914, D_loss_gen: 0.3126, Total loss: 2.3763, ratio: 1.9557\n",
            "Epoch [9/200], D_loss: 0.7148, G_loss: 1.5959, D_loss_real: 0.4080, D_loss_gen: 0.3068, Total loss: 2.3106, ratio: 2.2326\n",
            "Epoch [10/200], D_loss: 0.7790, G_loss: 1.7706, D_loss_real: 0.4829, D_loss_gen: 0.2961, Total loss: 2.5496, ratio: 2.2729\n",
            "Epoch [11/200], D_loss: 0.6987, G_loss: 1.4617, D_loss_real: 0.3603, D_loss_gen: 0.3384, Total loss: 2.1604, ratio: 2.0919\n",
            "Epoch [12/200], D_loss: 0.4813, G_loss: 2.0016, D_loss_real: 0.2780, D_loss_gen: 0.2032, Total loss: 2.4829, ratio: 4.1592\n",
            "Epoch [13/200], D_loss: 0.5877, G_loss: 1.6958, D_loss_real: 0.3114, D_loss_gen: 0.2763, Total loss: 2.2835, ratio: 2.8855\n",
            "Epoch [14/200], D_loss: 0.4309, G_loss: 1.7759, D_loss_real: 0.1486, D_loss_gen: 0.2823, Total loss: 2.2067, ratio: 4.1216\n",
            "Epoch [15/200], D_loss: 0.4433, G_loss: 2.1262, D_loss_real: 0.2190, D_loss_gen: 0.2242, Total loss: 2.5694, ratio: 4.7966\n",
            "Epoch [16/200], D_loss: 0.3560, G_loss: 2.5466, D_loss_real: 0.1439, D_loss_gen: 0.2121, Total loss: 2.9026, ratio: 7.1542\n",
            "Epoch [17/200], D_loss: 0.3879, G_loss: 2.2072, D_loss_real: 0.1923, D_loss_gen: 0.1955, Total loss: 2.5950, ratio: 5.6904\n",
            "Epoch [18/200], D_loss: 0.6261, G_loss: 2.0093, D_loss_real: 0.3923, D_loss_gen: 0.2338, Total loss: 2.6354, ratio: 3.2093\n",
            "Epoch [19/200], D_loss: 0.2664, G_loss: 2.3283, D_loss_real: 0.1110, D_loss_gen: 0.1554, Total loss: 2.5947, ratio: 8.7400\n",
            "Epoch [20/200], D_loss: 0.7542, G_loss: 2.2302, D_loss_real: 0.5493, D_loss_gen: 0.2049, Total loss: 2.9844, ratio: 2.9569\n",
            "Epoch [21/200], D_loss: 0.8229, G_loss: 1.7407, D_loss_real: 0.4457, D_loss_gen: 0.3771, Total loss: 2.5636, ratio: 2.1154\n",
            "Epoch [22/200], D_loss: 0.7622, G_loss: 1.3895, D_loss_real: 0.2761, D_loss_gen: 0.4861, Total loss: 2.1517, ratio: 1.8229\n",
            "Epoch [23/200], D_loss: 0.7648, G_loss: 1.7443, D_loss_real: 0.4366, D_loss_gen: 0.3282, Total loss: 2.5091, ratio: 2.2809\n",
            "Epoch [24/200], D_loss: 0.5294, G_loss: 1.6880, D_loss_real: 0.2319, D_loss_gen: 0.2975, Total loss: 2.2174, ratio: 3.1886\n",
            "Epoch [25/200], D_loss: 0.4468, G_loss: 2.1861, D_loss_real: 0.1894, D_loss_gen: 0.2574, Total loss: 2.6329, ratio: 4.8930\n",
            "Epoch [26/200], D_loss: 0.3353, G_loss: 2.1846, D_loss_real: 0.1192, D_loss_gen: 0.2161, Total loss: 2.5199, ratio: 6.5154\n",
            "Epoch [27/200], D_loss: 0.4140, G_loss: 2.0063, D_loss_real: 0.1239, D_loss_gen: 0.2901, Total loss: 2.4203, ratio: 4.8460\n",
            "Epoch [28/200], D_loss: 1.0259, G_loss: 1.7238, D_loss_real: 0.6766, D_loss_gen: 0.3493, Total loss: 2.7497, ratio: 1.6803\n",
            "Epoch [29/200], D_loss: 0.7422, G_loss: 1.7493, D_loss_real: 0.3870, D_loss_gen: 0.3551, Total loss: 2.4915, ratio: 2.3571\n",
            "Epoch [30/200], D_loss: 0.6064, G_loss: 1.9741, D_loss_real: 0.3308, D_loss_gen: 0.2756, Total loss: 2.5805, ratio: 3.2553\n",
            "Epoch [31/200], D_loss: 0.7623, G_loss: 2.1324, D_loss_real: 0.4958, D_loss_gen: 0.2666, Total loss: 2.8947, ratio: 2.7971\n",
            "Epoch [32/200], D_loss: 0.9987, G_loss: 1.5959, D_loss_real: 0.6515, D_loss_gen: 0.3472, Total loss: 2.5945, ratio: 1.5980\n",
            "Epoch [33/200], D_loss: 0.3436, G_loss: 2.3269, D_loss_real: 0.1978, D_loss_gen: 0.1458, Total loss: 2.6705, ratio: 6.7721\n",
            "Epoch [34/200], D_loss: 0.2892, G_loss: 2.6766, D_loss_real: 0.1440, D_loss_gen: 0.1452, Total loss: 2.9658, ratio: 9.2539\n",
            "Epoch [35/200], D_loss: 0.4854, G_loss: 2.4987, D_loss_real: 0.2534, D_loss_gen: 0.2320, Total loss: 2.9841, ratio: 5.1478\n",
            "Epoch [36/200], D_loss: 0.5164, G_loss: 2.2023, D_loss_real: 0.2464, D_loss_gen: 0.2700, Total loss: 2.7187, ratio: 4.2650\n",
            "Epoch [37/200], D_loss: 0.6713, G_loss: 2.2414, D_loss_real: 0.4872, D_loss_gen: 0.1841, Total loss: 2.9127, ratio: 3.3388\n",
            "Epoch [38/200], D_loss: 0.3729, G_loss: 2.6453, D_loss_real: 0.1821, D_loss_gen: 0.1908, Total loss: 3.0182, ratio: 7.0942\n",
            "Epoch [39/200], D_loss: 0.4579, G_loss: 2.5809, D_loss_real: 0.1948, D_loss_gen: 0.2631, Total loss: 3.0388, ratio: 5.6359\n",
            "Epoch [40/200], D_loss: 0.4860, G_loss: 2.4619, D_loss_real: 0.2655, D_loss_gen: 0.2204, Total loss: 2.9478, ratio: 5.0660\n",
            "Epoch [41/200], D_loss: 0.4083, G_loss: 2.2176, D_loss_real: 0.2161, D_loss_gen: 0.1922, Total loss: 2.6259, ratio: 5.4318\n",
            "Epoch [42/200], D_loss: 1.4041, G_loss: 1.4297, D_loss_real: 0.8241, D_loss_gen: 0.5800, Total loss: 2.8338, ratio: 1.0182\n",
            "Epoch [43/200], D_loss: 0.7563, G_loss: 1.7929, D_loss_real: 0.4338, D_loss_gen: 0.3225, Total loss: 2.5492, ratio: 2.3706\n",
            "Epoch [44/200], D_loss: 0.4259, G_loss: 2.2886, D_loss_real: 0.1569, D_loss_gen: 0.2690, Total loss: 2.7145, ratio: 5.3734\n",
            "Epoch [45/200], D_loss: 0.3079, G_loss: 2.5101, D_loss_real: 0.1301, D_loss_gen: 0.1777, Total loss: 2.8179, ratio: 8.1534\n",
            "Epoch [46/200], D_loss: 0.3875, G_loss: 2.6561, D_loss_real: 0.1973, D_loss_gen: 0.1902, Total loss: 3.0436, ratio: 6.8542\n",
            "Epoch [47/200], D_loss: 0.8737, G_loss: 2.2872, D_loss_real: 0.6169, D_loss_gen: 0.2568, Total loss: 3.1609, ratio: 2.6177\n",
            "Epoch [48/200], D_loss: 0.5675, G_loss: 2.0822, D_loss_real: 0.3016, D_loss_gen: 0.2659, Total loss: 2.6497, ratio: 3.6691\n",
            "Epoch [49/200], D_loss: 0.4013, G_loss: 2.4418, D_loss_real: 0.1823, D_loss_gen: 0.2190, Total loss: 2.8431, ratio: 6.0846\n",
            "Epoch [50/200], D_loss: 0.6936, G_loss: 2.4398, D_loss_real: 0.3432, D_loss_gen: 0.3504, Total loss: 3.1334, ratio: 3.5175\n",
            "Epoch [51/200], D_loss: 0.3582, G_loss: 2.5846, D_loss_real: 0.2189, D_loss_gen: 0.1393, Total loss: 2.9428, ratio: 7.2150\n",
            "Epoch [52/200], D_loss: 0.4504, G_loss: 2.7322, D_loss_real: 0.2478, D_loss_gen: 0.2026, Total loss: 3.1826, ratio: 6.0657\n",
            "Epoch [53/200], D_loss: 0.5283, G_loss: 2.2581, D_loss_real: 0.2969, D_loss_gen: 0.2313, Total loss: 2.7864, ratio: 4.2746\n",
            "Epoch [54/200], D_loss: 0.6289, G_loss: 2.2818, D_loss_real: 0.3228, D_loss_gen: 0.3061, Total loss: 2.9107, ratio: 3.6283\n",
            "Epoch [55/200], D_loss: 0.7239, G_loss: 2.2078, D_loss_real: 0.4516, D_loss_gen: 0.2724, Total loss: 2.9317, ratio: 3.0497\n",
            "Epoch [56/200], D_loss: 0.5752, G_loss: 2.6214, D_loss_real: 0.3775, D_loss_gen: 0.1977, Total loss: 3.1965, ratio: 4.5576\n",
            "Epoch [57/200], D_loss: 0.5331, G_loss: 1.8280, D_loss_real: 0.1446, D_loss_gen: 0.3884, Total loss: 2.3610, ratio: 3.4292\n",
            "Epoch [58/200], D_loss: 0.5518, G_loss: 2.0019, D_loss_real: 0.2441, D_loss_gen: 0.3078, Total loss: 2.5538, ratio: 3.6277\n",
            "Epoch [59/200], D_loss: 0.9680, G_loss: 1.5633, D_loss_real: 0.4253, D_loss_gen: 0.5426, Total loss: 2.5313, ratio: 1.6151\n",
            "Epoch [60/200], D_loss: 0.5286, G_loss: 1.9970, D_loss_real: 0.2810, D_loss_gen: 0.2476, Total loss: 2.5256, ratio: 3.7778\n",
            "Epoch [61/200], D_loss: 0.8110, G_loss: 2.1211, D_loss_real: 0.4784, D_loss_gen: 0.3326, Total loss: 2.9321, ratio: 2.6155\n",
            "Epoch [62/200], D_loss: 0.4023, G_loss: 2.4348, D_loss_real: 0.2061, D_loss_gen: 0.1962, Total loss: 2.8371, ratio: 6.0520\n",
            "Epoch [63/200], D_loss: 0.6844, G_loss: 2.3951, D_loss_real: 0.4372, D_loss_gen: 0.2471, Total loss: 3.0794, ratio: 3.4996\n",
            "Epoch [64/200], D_loss: 0.9438, G_loss: 2.1011, D_loss_real: 0.5557, D_loss_gen: 0.3880, Total loss: 3.0448, ratio: 2.2263\n",
            "Epoch [65/200], D_loss: 1.2532, G_loss: 1.1875, D_loss_real: 0.4826, D_loss_gen: 0.7706, Total loss: 2.4408, ratio: 0.9476\n",
            "Epoch [66/200], D_loss: 0.8351, G_loss: 1.2032, D_loss_real: 0.3713, D_loss_gen: 0.4639, Total loss: 2.0383, ratio: 1.4407\n",
            "Epoch [67/200], D_loss: 0.6096, G_loss: 1.7522, D_loss_real: 0.2917, D_loss_gen: 0.3179, Total loss: 2.3619, ratio: 2.8743\n",
            "Epoch [68/200], D_loss: 0.8421, G_loss: 1.7120, D_loss_real: 0.4896, D_loss_gen: 0.3525, Total loss: 2.5540, ratio: 2.0331\n",
            "Epoch [69/200], D_loss: 0.7968, G_loss: 2.2090, D_loss_real: 0.5163, D_loss_gen: 0.2805, Total loss: 3.0058, ratio: 2.7723\n",
            "Epoch [70/200], D_loss: 0.6469, G_loss: 1.9696, D_loss_real: 0.3218, D_loss_gen: 0.3251, Total loss: 2.6165, ratio: 3.0446\n",
            "Epoch [71/200], D_loss: 0.5925, G_loss: 1.7942, D_loss_real: 0.2941, D_loss_gen: 0.2984, Total loss: 2.3867, ratio: 3.0282\n",
            "Epoch [72/200], D_loss: 0.5500, G_loss: 2.0844, D_loss_real: 0.3043, D_loss_gen: 0.2457, Total loss: 2.6344, ratio: 3.7901\n",
            "Epoch [73/200], D_loss: 0.8014, G_loss: 1.6344, D_loss_real: 0.5227, D_loss_gen: 0.2787, Total loss: 2.4358, ratio: 2.0395\n",
            "Epoch [74/200], D_loss: 0.6854, G_loss: 1.8562, D_loss_real: 0.3938, D_loss_gen: 0.2916, Total loss: 2.5416, ratio: 2.7081\n",
            "Epoch [75/200], D_loss: 0.8620, G_loss: 1.3702, D_loss_real: 0.4635, D_loss_gen: 0.3985, Total loss: 2.2321, ratio: 1.5896\n",
            "Epoch [76/200], D_loss: 0.6382, G_loss: 2.1167, D_loss_real: 0.3034, D_loss_gen: 0.3347, Total loss: 2.7549, ratio: 3.3169\n",
            "Epoch [77/200], D_loss: 0.1998, G_loss: 2.7230, D_loss_real: 0.0501, D_loss_gen: 0.1497, Total loss: 2.9227, ratio: 13.6317\n",
            "Epoch [78/200], D_loss: 0.5956, G_loss: 1.8364, D_loss_real: 0.2842, D_loss_gen: 0.3114, Total loss: 2.4320, ratio: 3.0831\n",
            "Epoch [79/200], D_loss: 1.2074, G_loss: 1.4980, D_loss_real: 0.6613, D_loss_gen: 0.5461, Total loss: 2.7053, ratio: 1.2407\n",
            "Epoch [80/200], D_loss: 0.7158, G_loss: 2.0206, D_loss_real: 0.4367, D_loss_gen: 0.2790, Total loss: 2.7363, ratio: 2.8229\n",
            "Epoch [81/200], D_loss: 0.7497, G_loss: 2.0998, D_loss_real: 0.4524, D_loss_gen: 0.2973, Total loss: 2.8495, ratio: 2.8010\n",
            "Epoch [82/200], D_loss: 0.5162, G_loss: 1.9340, D_loss_real: 0.2286, D_loss_gen: 0.2876, Total loss: 2.4502, ratio: 3.7465\n",
            "Epoch [83/200], D_loss: 1.7371, G_loss: 0.8328, D_loss_real: 0.5872, D_loss_gen: 1.1500, Total loss: 2.5699, ratio: 0.4794\n",
            "Epoch [84/200], D_loss: 0.3325, G_loss: 1.4629, D_loss_real: 0.0038, D_loss_gen: 0.3287, Total loss: 1.7954, ratio: 4.3995\n",
            "Epoch [85/200], D_loss: 0.0283, G_loss: 3.9138, D_loss_real: 0.0003, D_loss_gen: 0.0281, Total loss: 3.9421, ratio: 138.1255\n",
            "Epoch [86/200], D_loss: 0.0067, G_loss: 5.1733, D_loss_real: 0.0001, D_loss_gen: 0.0065, Total loss: 5.1800, ratio: 776.9095\n",
            "Epoch [87/200], D_loss: 0.0050, G_loss: 5.5437, D_loss_real: 0.0000, D_loss_gen: 0.0049, Total loss: 5.5486, ratio: 1117.5884\n",
            "Epoch [88/200], D_loss: 0.0011, G_loss: 7.0493, D_loss_real: 0.0001, D_loss_gen: 0.0011, Total loss: 7.0504, ratio: 6152.9261\n",
            "Epoch [89/200], D_loss: 0.0004, G_loss: 8.7039, D_loss_real: 0.0000, D_loss_gen: 0.0004, Total loss: 8.7043, ratio: 22092.1654\n",
            "Epoch [90/200], D_loss: 0.0067, G_loss: 8.1826, D_loss_real: 0.0002, D_loss_gen: 0.0066, Total loss: 8.1893, ratio: 1219.0664\n",
            "Epoch [91/200], D_loss: 0.1015, G_loss: 6.4883, D_loss_real: 0.0552, D_loss_gen: 0.0463, Total loss: 6.5898, ratio: 63.9436\n",
            "Epoch [92/200], D_loss: 0.1012, G_loss: 5.2490, D_loss_real: 0.0180, D_loss_gen: 0.0832, Total loss: 5.3502, ratio: 51.8789\n",
            "Epoch [93/200], D_loss: 1.8892, G_loss: 2.3236, D_loss_real: 1.0109, D_loss_gen: 0.8783, Total loss: 4.2128, ratio: 1.2299\n",
            "Epoch [94/200], D_loss: 1.2448, G_loss: 1.8270, D_loss_real: 0.6264, D_loss_gen: 0.6185, Total loss: 3.0719, ratio: 1.4677\n",
            "Epoch [95/200], D_loss: 0.7302, G_loss: 1.8065, D_loss_real: 0.3770, D_loss_gen: 0.3532, Total loss: 2.5367, ratio: 2.4741\n",
            "Epoch [96/200], D_loss: 0.5907, G_loss: 1.9594, D_loss_real: 0.3160, D_loss_gen: 0.2747, Total loss: 2.5500, ratio: 3.3172\n",
            "Epoch [97/200], D_loss: 1.1394, G_loss: 1.6771, D_loss_real: 0.7103, D_loss_gen: 0.4291, Total loss: 2.8164, ratio: 1.4719\n",
            "Epoch [98/200], D_loss: 1.3271, G_loss: 1.5084, D_loss_real: 0.6941, D_loss_gen: 0.6330, Total loss: 2.8355, ratio: 1.1366\n",
            "Epoch [99/200], D_loss: 0.7949, G_loss: 1.8479, D_loss_real: 0.4191, D_loss_gen: 0.3758, Total loss: 2.6428, ratio: 2.3248\n",
            "Epoch [100/200], D_loss: 0.9095, G_loss: 1.6066, D_loss_real: 0.4279, D_loss_gen: 0.4815, Total loss: 2.5161, ratio: 1.7666\n",
            "Epoch [101/200], D_loss: 0.6092, G_loss: 1.7295, D_loss_real: 0.3122, D_loss_gen: 0.2970, Total loss: 2.3387, ratio: 2.8388\n",
            "Epoch [102/200], D_loss: 1.0585, G_loss: 1.5595, D_loss_real: 0.4747, D_loss_gen: 0.5837, Total loss: 2.6179, ratio: 1.4733\n",
            "Epoch [103/200], D_loss: 1.0600, G_loss: 1.6279, D_loss_real: 0.6056, D_loss_gen: 0.4544, Total loss: 2.6879, ratio: 1.5357\n",
            "Epoch [104/200], D_loss: 0.5924, G_loss: 1.8730, D_loss_real: 0.2722, D_loss_gen: 0.3202, Total loss: 2.4654, ratio: 3.1617\n",
            "Epoch [105/200], D_loss: 0.5773, G_loss: 1.9213, D_loss_real: 0.2700, D_loss_gen: 0.3073, Total loss: 2.4986, ratio: 3.3283\n",
            "Epoch [106/200], D_loss: 0.5527, G_loss: 1.7047, D_loss_real: 0.2719, D_loss_gen: 0.2808, Total loss: 2.2574, ratio: 3.0845\n",
            "Epoch [107/200], D_loss: 1.3011, G_loss: 1.2969, D_loss_real: 0.5934, D_loss_gen: 0.7077, Total loss: 2.5979, ratio: 0.9968\n",
            "Epoch [108/200], D_loss: 0.7366, G_loss: 2.1400, D_loss_real: 0.4319, D_loss_gen: 0.3046, Total loss: 2.8766, ratio: 2.9055\n",
            "Epoch [109/200], D_loss: 0.6175, G_loss: 1.6806, D_loss_real: 0.3260, D_loss_gen: 0.2915, Total loss: 2.2981, ratio: 2.7216\n",
            "Epoch [110/200], D_loss: 0.7252, G_loss: 1.8017, D_loss_real: 0.3975, D_loss_gen: 0.3277, Total loss: 2.5270, ratio: 2.4843\n",
            "Epoch [111/200], D_loss: 1.0724, G_loss: 1.7382, D_loss_real: 0.7555, D_loss_gen: 0.3169, Total loss: 2.8106, ratio: 1.6209\n",
            "Epoch [112/200], D_loss: 0.5145, G_loss: 2.0024, D_loss_real: 0.2635, D_loss_gen: 0.2510, Total loss: 2.5169, ratio: 3.8921\n",
            "Epoch [113/200], D_loss: 0.8654, G_loss: 1.8751, D_loss_real: 0.5804, D_loss_gen: 0.2851, Total loss: 2.7405, ratio: 2.1667\n",
            "Epoch [114/200], D_loss: 0.6868, G_loss: 1.9585, D_loss_real: 0.3946, D_loss_gen: 0.2923, Total loss: 2.6454, ratio: 2.8515\n",
            "Epoch [115/200], D_loss: 0.7833, G_loss: 1.7829, D_loss_real: 0.4287, D_loss_gen: 0.3546, Total loss: 2.5662, ratio: 2.2762\n",
            "Epoch [116/200], D_loss: 0.7186, G_loss: 1.8572, D_loss_real: 0.4457, D_loss_gen: 0.2729, Total loss: 2.5758, ratio: 2.5845\n",
            "Epoch [117/200], D_loss: 0.8959, G_loss: 1.7401, D_loss_real: 0.5270, D_loss_gen: 0.3689, Total loss: 2.6360, ratio: 1.9424\n",
            "Epoch [118/200], D_loss: 0.5015, G_loss: 1.9533, D_loss_real: 0.2314, D_loss_gen: 0.2701, Total loss: 2.4548, ratio: 3.8950\n",
            "Epoch [119/200], D_loss: 0.6729, G_loss: 1.9789, D_loss_real: 0.4216, D_loss_gen: 0.2514, Total loss: 2.6519, ratio: 2.9408\n",
            "Epoch [120/200], D_loss: 0.6779, G_loss: 1.7484, D_loss_real: 0.3713, D_loss_gen: 0.3065, Total loss: 2.4262, ratio: 2.5793\n",
            "Epoch [121/200], D_loss: 0.6325, G_loss: 1.8862, D_loss_real: 0.3816, D_loss_gen: 0.2509, Total loss: 2.5187, ratio: 2.9823\n",
            "Epoch [122/200], D_loss: 0.6273, G_loss: 2.2290, D_loss_real: 0.3520, D_loss_gen: 0.2754, Total loss: 2.8564, ratio: 3.5531\n",
            "Epoch [123/200], D_loss: 0.7337, G_loss: 1.8433, D_loss_real: 0.3398, D_loss_gen: 0.3939, Total loss: 2.5770, ratio: 2.5123\n",
            "Epoch [124/200], D_loss: 0.6136, G_loss: 1.8929, D_loss_real: 0.3543, D_loss_gen: 0.2592, Total loss: 2.5064, ratio: 3.0849\n",
            "Epoch [125/200], D_loss: 0.5092, G_loss: 1.9213, D_loss_real: 0.1788, D_loss_gen: 0.3304, Total loss: 2.4305, ratio: 3.7729\n",
            "Epoch [126/200], D_loss: 0.7321, G_loss: 1.3733, D_loss_real: 0.3418, D_loss_gen: 0.3903, Total loss: 2.1054, ratio: 1.8757\n",
            "Epoch [127/200], D_loss: 0.6597, G_loss: 1.7098, D_loss_real: 0.3444, D_loss_gen: 0.3153, Total loss: 2.3695, ratio: 2.5919\n",
            "Epoch [128/200], D_loss: 0.7750, G_loss: 1.4595, D_loss_real: 0.3952, D_loss_gen: 0.3798, Total loss: 2.2345, ratio: 1.8832\n",
            "Epoch [129/200], D_loss: 0.6352, G_loss: 1.9198, D_loss_real: 0.3385, D_loss_gen: 0.2967, Total loss: 2.5549, ratio: 3.0225\n",
            "Epoch [130/200], D_loss: 0.8749, G_loss: 1.6232, D_loss_real: 0.5440, D_loss_gen: 0.3309, Total loss: 2.4981, ratio: 1.8553\n",
            "Epoch [131/200], D_loss: 0.7238, G_loss: 1.9147, D_loss_real: 0.4540, D_loss_gen: 0.2698, Total loss: 2.6386, ratio: 2.6452\n",
            "Epoch [132/200], D_loss: 0.6844, G_loss: 1.9959, D_loss_real: 0.3915, D_loss_gen: 0.2928, Total loss: 2.6803, ratio: 2.9165\n",
            "Epoch [133/200], D_loss: 0.6816, G_loss: 1.8156, D_loss_real: 0.3101, D_loss_gen: 0.3715, Total loss: 2.4972, ratio: 2.6637\n",
            "Epoch [134/200], D_loss: 0.7594, G_loss: 2.0590, D_loss_real: 0.4786, D_loss_gen: 0.2808, Total loss: 2.8184, ratio: 2.7112\n",
            "Epoch [135/200], D_loss: 0.8110, G_loss: 1.8502, D_loss_real: 0.4642, D_loss_gen: 0.3467, Total loss: 2.6612, ratio: 2.2815\n",
            "Epoch [136/200], D_loss: 0.6507, G_loss: 1.5395, D_loss_real: 0.2958, D_loss_gen: 0.3548, Total loss: 2.1902, ratio: 2.3661\n",
            "Epoch [137/200], D_loss: 0.5672, G_loss: 2.1589, D_loss_real: 0.3498, D_loss_gen: 0.2174, Total loss: 2.7261, ratio: 3.8061\n",
            "Epoch [138/200], D_loss: 0.5499, G_loss: 1.8966, D_loss_real: 0.2597, D_loss_gen: 0.2902, Total loss: 2.4465, ratio: 3.4488\n",
            "Epoch [139/200], D_loss: 1.5414, G_loss: 0.8127, D_loss_real: 0.4511, D_loss_gen: 1.0903, Total loss: 2.3541, ratio: 0.5272\n",
            "Epoch [140/200], D_loss: 0.7294, G_loss: 1.5583, D_loss_real: 0.3855, D_loss_gen: 0.3438, Total loss: 2.2877, ratio: 2.1365\n",
            "Epoch [141/200], D_loss: 0.6457, G_loss: 1.8999, D_loss_real: 0.3175, D_loss_gen: 0.3281, Total loss: 2.5456, ratio: 2.9424\n",
            "Epoch [142/200], D_loss: 0.8799, G_loss: 1.6071, D_loss_real: 0.3784, D_loss_gen: 0.5015, Total loss: 2.4869, ratio: 1.8264\n",
            "Epoch [143/200], D_loss: 0.8409, G_loss: 1.7255, D_loss_real: 0.5428, D_loss_gen: 0.2981, Total loss: 2.5663, ratio: 2.0521\n",
            "Epoch [144/200], D_loss: 0.7090, G_loss: 2.1671, D_loss_real: 0.4782, D_loss_gen: 0.2307, Total loss: 2.8761, ratio: 3.0568\n",
            "Epoch [145/200], D_loss: 0.7813, G_loss: 1.9577, D_loss_real: 0.4972, D_loss_gen: 0.2841, Total loss: 2.7391, ratio: 2.5056\n",
            "Epoch [146/200], D_loss: 0.6963, G_loss: 1.7194, D_loss_real: 0.4201, D_loss_gen: 0.2763, Total loss: 2.4158, ratio: 2.4693\n",
            "Epoch [147/200], D_loss: 0.7048, G_loss: 1.8178, D_loss_real: 0.4261, D_loss_gen: 0.2787, Total loss: 2.5225, ratio: 2.5791\n",
            "Epoch [148/200], D_loss: 0.6764, G_loss: 2.0902, D_loss_real: 0.3913, D_loss_gen: 0.2852, Total loss: 2.7667, ratio: 3.0900\n",
            "Epoch [149/200], D_loss: 0.5428, G_loss: 2.2694, D_loss_real: 0.3758, D_loss_gen: 0.1671, Total loss: 2.8123, ratio: 4.1807\n",
            "Epoch [150/200], D_loss: 1.4645, G_loss: 1.0065, D_loss_real: 0.5106, D_loss_gen: 0.9539, Total loss: 2.4711, ratio: 0.6873\n",
            "Epoch [151/200], D_loss: 1.0308, G_loss: 1.2424, D_loss_real: 0.6084, D_loss_gen: 0.4225, Total loss: 2.2733, ratio: 1.2053\n",
            "Epoch [152/200], D_loss: 0.7759, G_loss: 1.4012, D_loss_real: 0.4116, D_loss_gen: 0.3643, Total loss: 2.1772, ratio: 1.8059\n",
            "Epoch [153/200], D_loss: 0.6617, G_loss: 1.6030, D_loss_real: 0.3590, D_loss_gen: 0.3027, Total loss: 2.2647, ratio: 2.4227\n",
            "Epoch [154/200], D_loss: 0.6858, G_loss: 1.8077, D_loss_real: 0.3908, D_loss_gen: 0.2950, Total loss: 2.4935, ratio: 2.6359\n",
            "Epoch [155/200], D_loss: 0.6018, G_loss: 2.0095, D_loss_real: 0.3165, D_loss_gen: 0.2852, Total loss: 2.6113, ratio: 3.3393\n",
            "Epoch [156/200], D_loss: 0.9742, G_loss: 1.6006, D_loss_real: 0.6375, D_loss_gen: 0.3367, Total loss: 2.5747, ratio: 1.6430\n",
            "Epoch [157/200], D_loss: 0.8369, G_loss: 1.8711, D_loss_real: 0.5533, D_loss_gen: 0.2837, Total loss: 2.7080, ratio: 2.2356\n",
            "Epoch [158/200], D_loss: 0.8319, G_loss: 1.5305, D_loss_real: 0.3481, D_loss_gen: 0.4839, Total loss: 2.3625, ratio: 1.8397\n",
            "Epoch [159/200], D_loss: 0.6048, G_loss: 1.7703, D_loss_real: 0.3537, D_loss_gen: 0.2510, Total loss: 2.3750, ratio: 2.9273\n",
            "Epoch [160/200], D_loss: 0.8873, G_loss: 1.7469, D_loss_real: 0.4891, D_loss_gen: 0.3982, Total loss: 2.6342, ratio: 1.9688\n",
            "Epoch [161/200], D_loss: 0.7515, G_loss: 1.7248, D_loss_real: 0.4080, D_loss_gen: 0.3435, Total loss: 2.4763, ratio: 2.2953\n",
            "Epoch [162/200], D_loss: 0.6929, G_loss: 1.9304, D_loss_real: 0.3712, D_loss_gen: 0.3217, Total loss: 2.6233, ratio: 2.7859\n",
            "Epoch [163/200], D_loss: 0.6406, G_loss: 1.7819, D_loss_real: 0.3472, D_loss_gen: 0.2935, Total loss: 2.4226, ratio: 2.7815\n",
            "Epoch [164/200], D_loss: 1.2869, G_loss: 1.5506, D_loss_real: 0.6813, D_loss_gen: 0.6056, Total loss: 2.8375, ratio: 1.2050\n",
            "Epoch [165/200], D_loss: 0.6665, G_loss: 1.8144, D_loss_real: 0.3937, D_loss_gen: 0.2728, Total loss: 2.4810, ratio: 2.7223\n",
            "Epoch [166/200], D_loss: 0.8232, G_loss: 1.8132, D_loss_real: 0.5266, D_loss_gen: 0.2966, Total loss: 2.6364, ratio: 2.2027\n",
            "Epoch [167/200], D_loss: 0.6687, G_loss: 1.7153, D_loss_real: 0.2593, D_loss_gen: 0.4095, Total loss: 2.3840, ratio: 2.5649\n",
            "Epoch [168/200], D_loss: 0.5665, G_loss: 2.0991, D_loss_real: 0.3092, D_loss_gen: 0.2574, Total loss: 2.6657, ratio: 3.7051\n",
            "Epoch [169/200], D_loss: 0.8773, G_loss: 1.4895, D_loss_real: 0.4404, D_loss_gen: 0.4369, Total loss: 2.3668, ratio: 1.6980\n",
            "Epoch [170/200], D_loss: 0.8089, G_loss: 1.5993, D_loss_real: 0.4369, D_loss_gen: 0.3720, Total loss: 2.4082, ratio: 1.9771\n",
            "Epoch [171/200], D_loss: 0.6504, G_loss: 1.9910, D_loss_real: 0.3808, D_loss_gen: 0.2696, Total loss: 2.6414, ratio: 3.0613\n",
            "Epoch [172/200], D_loss: 0.8379, G_loss: 1.6115, D_loss_real: 0.5080, D_loss_gen: 0.3299, Total loss: 2.4495, ratio: 1.9233\n",
            "Epoch [173/200], D_loss: 0.8385, G_loss: 1.8760, D_loss_real: 0.4447, D_loss_gen: 0.3938, Total loss: 2.7144, ratio: 2.2374\n",
            "Epoch [174/200], D_loss: 0.8623, G_loss: 1.6694, D_loss_real: 0.4974, D_loss_gen: 0.3650, Total loss: 2.5318, ratio: 1.9359\n",
            "Epoch [175/200], D_loss: 0.6331, G_loss: 2.0756, D_loss_real: 0.3143, D_loss_gen: 0.3188, Total loss: 2.7087, ratio: 3.2783\n",
            "Epoch [176/200], D_loss: 0.7007, G_loss: 1.9539, D_loss_real: 0.3614, D_loss_gen: 0.3393, Total loss: 2.6546, ratio: 2.7886\n",
            "Epoch [177/200], D_loss: 0.7756, G_loss: 1.6553, D_loss_real: 0.4351, D_loss_gen: 0.3405, Total loss: 2.4309, ratio: 2.1343\n",
            "Epoch [178/200], D_loss: 0.7234, G_loss: 1.8058, D_loss_real: 0.3342, D_loss_gen: 0.3892, Total loss: 2.5291, ratio: 2.4964\n",
            "Epoch [179/200], D_loss: 0.8041, G_loss: 1.9279, D_loss_real: 0.5128, D_loss_gen: 0.2913, Total loss: 2.7320, ratio: 2.3975\n",
            "Epoch [180/200], D_loss: 0.6124, G_loss: 2.2948, D_loss_real: 0.3383, D_loss_gen: 0.2742, Total loss: 2.9072, ratio: 3.7469\n",
            "Epoch [181/200], D_loss: 0.7921, G_loss: 1.9066, D_loss_real: 0.4021, D_loss_gen: 0.3900, Total loss: 2.6987, ratio: 2.4070\n",
            "Epoch [182/200], D_loss: 0.7713, G_loss: 2.0784, D_loss_real: 0.5464, D_loss_gen: 0.2249, Total loss: 2.8497, ratio: 2.6946\n",
            "Epoch [183/200], D_loss: 0.5662, G_loss: 2.2639, D_loss_real: 0.3439, D_loss_gen: 0.2224, Total loss: 2.8301, ratio: 3.9982\n",
            "Epoch [184/200], D_loss: 0.7129, G_loss: 1.8311, D_loss_real: 0.3148, D_loss_gen: 0.3981, Total loss: 2.5440, ratio: 2.5684\n",
            "Epoch [185/200], D_loss: 0.7308, G_loss: 1.7260, D_loss_real: 0.3130, D_loss_gen: 0.4178, Total loss: 2.4568, ratio: 2.3619\n",
            "Epoch [186/200], D_loss: 0.7176, G_loss: 1.9569, D_loss_real: 0.4440, D_loss_gen: 0.2736, Total loss: 2.6744, ratio: 2.7270\n",
            "Epoch [187/200], D_loss: 0.5918, G_loss: 2.0296, D_loss_real: 0.3065, D_loss_gen: 0.2853, Total loss: 2.6214, ratio: 3.4293\n",
            "Epoch [188/200], D_loss: 0.5753, G_loss: 2.0527, D_loss_real: 0.3191, D_loss_gen: 0.2562, Total loss: 2.6280, ratio: 3.5680\n",
            "Epoch [189/200], D_loss: 0.6252, G_loss: 1.8255, D_loss_real: 0.2631, D_loss_gen: 0.3621, Total loss: 2.4507, ratio: 2.9198\n",
            "Epoch [190/200], D_loss: 0.5040, G_loss: 1.8949, D_loss_real: 0.2006, D_loss_gen: 0.3034, Total loss: 2.3989, ratio: 3.7597\n",
            "Epoch [191/200], D_loss: 0.7903, G_loss: 1.9728, D_loss_real: 0.5182, D_loss_gen: 0.2721, Total loss: 2.7631, ratio: 2.4963\n",
            "Epoch [192/200], D_loss: 0.6408, G_loss: 2.0126, D_loss_real: 0.2927, D_loss_gen: 0.3481, Total loss: 2.6534, ratio: 3.1405\n",
            "Epoch [193/200], D_loss: 0.5395, G_loss: 2.1556, D_loss_real: 0.2572, D_loss_gen: 0.2823, Total loss: 2.6951, ratio: 3.9952\n",
            "Epoch [194/200], D_loss: 0.6250, G_loss: 1.8870, D_loss_real: 0.2701, D_loss_gen: 0.3548, Total loss: 2.5120, ratio: 3.0194\n",
            "Epoch [195/200], D_loss: 0.6787, G_loss: 1.7438, D_loss_real: 0.3026, D_loss_gen: 0.3761, Total loss: 2.4225, ratio: 2.5694\n",
            "Epoch [196/200], D_loss: 0.6106, G_loss: 2.0767, D_loss_real: 0.4089, D_loss_gen: 0.2017, Total loss: 2.6873, ratio: 3.4009\n",
            "Epoch [197/200], D_loss: 0.9111, G_loss: 1.9981, D_loss_real: 0.6062, D_loss_gen: 0.3049, Total loss: 2.9092, ratio: 2.1929\n",
            "Epoch [198/200], D_loss: 0.5452, G_loss: 2.4249, D_loss_real: 0.2544, D_loss_gen: 0.2908, Total loss: 2.9701, ratio: 4.4481\n",
            "Epoch [199/200], D_loss: 0.5002, G_loss: 2.2639, D_loss_real: 0.2056, D_loss_gen: 0.2946, Total loss: 2.7641, ratio: 4.5262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 8305 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbafGauylvFG",
        "outputId": "15d794f3-59eb-4bd3-9ced-4be39fe1e206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#plot losses and generated images\n",
        "noise = torch.tensor(draw_sample(9, zdim), dtype=torch.float32).to(device)\n",
        "samples = G(noise)\n",
        "# samples = get_n_samples(data_loader, 9)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(10, 10)\n",
        "for j, sample in enumerate(samples):\n",
        "    sample = sample.detach().cpu().numpy()\n",
        "    ax = plt.subplot(gs[j])\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "plt.savefig('/content/res/{}.png'.format(str(j).zfill(7)), bbox_inches='tight')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIgCE4Y5lvFG"
      },
      "source": [
        "## 2a. Implement GAN with Convolutional architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSHWiNGVlvFG"
      },
      "source": [
        "Convolurional neural networks (CNNs) have a better feature representation, unlike, fully connected layers. Hence, it is required here to modify your code to include CNNs in your script. For more information, check out this [tutorial](https://gucifer.github.io/mediator/feature/2021/08/11/GAN-evaluation-using-FID-and-IS.html).\n",
        "\n",
        "Similar to before, please report your training performance i.e. train loss as a figure and another figure containing a batch of generated images after training. You can plot one figure including and highlight the train loss using fully connected and CNN networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EqFLkGjOlvFH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "kLlKjWnHlvFH",
        "outputId": "ced74317-7b22-4ba4-9b68-4c09fc00ab96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "#load MNIST\n",
        "\n",
        "data_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize([32, 32]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(0.5, 0.5),\n",
        "    ]\n",
        ")\n",
        "\n",
        "params = dict(\n",
        "  num_epochs = 20,\n",
        "  batch_size = 64,\n",
        "  learning_rate = 0.0002,\n",
        "  momentum=1e-4,\n",
        "  fashion_mnist = False\n",
        ")\n",
        "\n",
        "if params['fashion_mnist'] == False:\n",
        "    dataset = datasets.MNIST('MNIST_data', train=True, download=True, transform=data_transform)\n",
        "else:\n",
        "    dataset = datasets.FashionMNIST('Fashion-MNIST_data', train=True, download=True, transform=data_transform)\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "9S3Y5erqlvFI"
      },
      "outputs": [],
      "source": [
        "#setup convolutional generator\n",
        "class CNN_Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, feature_maps=64, img_channels=1):\n",
        "        super(CNN_Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # Input: latent_dim x 1 x 1\n",
        "            nn.ConvTranspose2d(latent_dim, feature_maps * 4, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(feature_maps * 4),\n",
        "            nn.ReLU(True),\n",
        "            # State: (feature_maps * 4) x 4 x 4\n",
        "\n",
        "            nn.ConvTranspose2d(feature_maps * 4, feature_maps * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(feature_maps * 2),\n",
        "            nn.ReLU(True),\n",
        "            # State: (feature_maps * 2) x 8 x 8\n",
        "\n",
        "            nn.ConvTranspose2d(feature_maps * 2, feature_maps, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(feature_maps),\n",
        "            nn.ReLU(True),\n",
        "            # State: feature_maps x 16 x 16\n",
        "\n",
        "            nn.ConvTranspose2d(feature_maps, img_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Output: img_channels x 28 x 28\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "gen = CNN_Generator(latent_dim)\n",
        "example_img = data_loader.dataset[0][0] # single image from a dataset\n",
        "noise = torch.randn(1, latent_dim, 1, 1, device=device) # generating a single latent vecotr for testing\n",
        "generated_noise = gen(noise)"
      ],
      "metadata": {
        "id": "lkN3iaV7FEl1"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "K2tR7uMglvFI"
      },
      "outputs": [],
      "source": [
        "#setup convolutional discriminator\n",
        "class CNN_Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim, feature_maps=64, img_channels=1):\n",
        "        super(CNN_Discriminator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.feature_maps = feature_maps\n",
        "        self.img_channels = img_channels\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(self.img_channels, self.feature_maps, 4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(self.feature_maps, self.feature_maps * 2, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(self.feature_maps * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(self.feature_maps * 2, self.feature_maps * 4, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(feature_maps * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(self.feature_maps * 4, self.latent_dim, 4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(latent_dim),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(self.latent_dim, 1, 1, stride=1, padding=0, bias=False),\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"parameters shape\", self.latent_dim, self.feature_maps, self.img_channels)\n",
        "        # print(\"input shape\", x.shape)\n",
        "        logits = self.model(x)\n",
        "        res = self.sigmoid(logits)\n",
        "        return logits, res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc = CNN_Discriminator(latent_dim)\n",
        "duplicated_tensor = generated_noise.repeat(2, 1, 1, 1) # duplicate the tensor to make it (2, 100, 1, 1) so it can run through the discriminator\n",
        "log, result = disc(duplicated_tensor)\n",
        "print(log.shape)"
      ],
      "metadata": {
        "id": "jJkwqy4BW1rP",
        "outputId": "9d299b31-a58a-4144-9814-7d8958670c32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(gen)\n",
        "print(f\"Total trainable (generator) parameters: {total_params}\")\n",
        "total_params = count_parameters(disc)\n",
        "print(f\"Total trainable (discriminator) parameters: {total_params}\")"
      ],
      "metadata": {
        "id": "JtDwMGx5ldlF",
        "outputId": "0d0b1fef-1570-4079-babe-6caff53a46a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable (generator) parameters: 1066880\n",
            "Total trainable (discriminator) parameters: 1067052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sample\n",
        "def draw_sample(sample_shape):\n",
        "    return np.random.uniform(-1.0, 1.0, size=sample_shape).astype(np.float32)"
      ],
      "metadata": {
        "id": "vXvRGHJ1hYIK"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "# x = torch.tensor(draw_sample(1, 784), dtype=torch.float32).to(device)\n",
        "# z = torch.tensor(draw_sample(1, zdim), dtype=torch.float32).to(device)\n",
        "\n",
        "G = CNN_Generator(latent_dim).to(device)\n",
        "D = CNN_Discriminator(latent_dim).to(device)\n",
        "\n",
        "# G_sample_train = G(z)\n",
        "# D_logit_real, D_real = D(x)\n",
        "# D_logit_gen, D_fake = D(G_sample_train.detach())\n",
        "# G_sample_inf = G(z)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# D_loss_real = criterion(D_logit_real, torch.ones_like(D_logit_real))\n",
        "# D_loss_gen = criterion(D_logit_gen, torch.zeros_like(D_logit_gen))\n",
        "# D_loss = D_loss_real + D_loss_gen\n",
        "\n",
        "# G_loss = criterion(D_logit_gen, torch.ones_like(D_logit_gen))\n",
        "\n",
        "opt_g = optim.Adam(G.parameters(), lr=0.0002, betas=(0.8, 0.999))\n",
        "opt_d = optim.Adam(D.parameters(), lr=0.0001, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "VIpMejy-g2Gc"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "lIkhQi8FlvFI",
        "outputId": "c76ce5a6-ca64-4d8b-b0b6-9695e2c24d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-9ef61dbdf84d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# print(real_imgs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mD_logit_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mD_logit_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_sample_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mD_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_logit_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_logit_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-177-9c2ac1f51000>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# print(\"parameters shape\", self.latent_dim, self.feature_maps, self.img_channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# print(\"input shape\", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training loop\n",
        "\n",
        "for epoch in range(params['num_epochs']):\n",
        "    for batch_idx, (real_imgs, _) in enumerate(data_loader):\n",
        "        # Update discriminator\n",
        "        z = torch.tensor(draw_sample((params['batch_size'], latent_dim, 1, 1))).to(device)\n",
        "\n",
        "        opt_d.zero_grad()\n",
        "\n",
        "        G_sample_train = G(z)\n",
        "        # print(real_imgs.shape)\n",
        "        D_logit_real, D_real = D(real_imgs)\n",
        "        D_logit_gen, D_fake = D(G_sample_train.detach())\n",
        "\n",
        "        D_loss_real = criterion(D_logit_real, torch.ones_like(D_logit_real))\n",
        "        D_loss_gen = criterion(D_logit_gen, torch.zeros_like(D_logit_gen))\n",
        "        D_loss = D_loss_real + D_loss_gen\n",
        "\n",
        "        D_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(D.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        opt_d.step()\n",
        "\n",
        "        # Update generator\n",
        "        # z = torch.tensor(draw_sample(params['batch_size'], zdim)).to(device)\n",
        "        opt_g.zero_grad()\n",
        "\n",
        "        # G_sample_train = G(z)\n",
        "        D_logit_gen, D_fake = D(G_sample_train)\n",
        "\n",
        "        G_loss = criterion(D_logit_gen, torch.ones_like(D_logit_gen))\n",
        "\n",
        "        G_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(G.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        opt_g.step()\n",
        "\n",
        "    # if epoch % 20 == 0:\n",
        "    print(f'Epoch [{epoch}/{params[\"num_epochs\"]}], D_loss: {D_loss.item():.4f}, G_loss: {G_loss.item():.4f}, D_loss_real: {D_loss_real.item():.4f}, D_loss_gen: {D_loss_gen.item():.4f}, Total loss: {G_loss.item() + D_loss.item():.4f}, ratio: {G_loss.item() / D_loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b80phoMlvFI"
      },
      "outputs": [],
      "source": [
        "#plot losses and generated images with the convolutional GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPQ6rbv3lvFJ"
      },
      "source": [
        "## 2b. now reimplement this with FASHION-MNIST with a convolutinal architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iKIHCMJlvFJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_7esjHhlvFJ"
      },
      "source": [
        "## 3. Conditional GAN (cGAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijgYYRhJlvFJ"
      },
      "source": [
        "Vanilla GANs produce synthetic images by drawing a random vector from latent space. However, we may condition the GAN to additional information, namely, a class label e.g. label  \"0\" in MNIST. This requires to additionally input the label to G and D networks along with random vector drawn from latent space. You may use this [cGAN](https://learnopencv.com/conditional-gan-cgan-in-pytorch-and-tensorflow/) tutorial to implement a cGAN based on the convolutional archiecture you've implemented before. Furthermore, MNIST should be used in this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XDWRaCglvFJ"
      },
      "outputs": [],
      "source": [
        "#generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKCnYTQYlvFJ"
      },
      "outputs": [],
      "source": [
        "#define training step for generator\n",
        "\n",
        "#define training step for discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJlb9UoWlvFK"
      },
      "outputs": [],
      "source": [
        "#training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whJJlqp6lvFK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k14z6nxlvFK"
      },
      "outputs": [],
      "source": [
        "#plot looses and generated images along wth their conditions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}