{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubejda/Advanced_DL/blob/main/Few_Shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ29SVQ3nb6I"
      },
      "source": [
        "![alternatvie text](https://www.doc.zuv.fau.de//M/FAU-Logo/01_FAU_Kernmarke/Web/FAU_Kernmarke_Q_RGB_blue.svg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05T_2g2Anb6L"
      },
      "source": [
        "# Assignment 5: Few-Shot Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6HBie3-nb6L"
      },
      "source": [
        "In the lecture you have learned optimization-based meta-learning techniques with application to few-shot image classification and segmentation. In this notebook, you'll be implementing First-order MAML (FOMAML) and Reptile algorithms for few-shot image classification task. You'll use CIFAR-FS dataset throughout this exercise.\n",
        "\n",
        "Note: You are required to install [**torchmeta**](https://github.com/tristandeleu/pytorch-meta) to assist you in your assignment. Also, note that this library support PyTorch up to version 1.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRojAPX4nb6M"
      },
      "source": [
        "## 1) Task Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbiOC12knb6M"
      },
      "source": [
        "In this task, you'll be required to implement a task generator for few-shot classification using torchmeta. Subsquently, the generator will be used as argument in the Dataloader for training and testing with FOMAML and Reptile. Recall a few-shot classification task is formulated as *N*-way, *K*-shot problem, where the *NK* data samples form the support set. Set *N* = 5 and *K*=5. Also, set the size of the query set to 15. The below figure visulaizes a few-shot classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftoROdpOnb6N"
      },
      "source": [
        "<img src=\"task.png\" width=\"250\" height=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebyN7Unlnb6N"
      },
      "source": [
        "Omniglot dataset contains handwritten characters from different alphabets, visualize some of the dataset samples below. You'll use the train set in meta-training and the test set for meta-testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install learn2learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MPBJ5z9znlWc",
        "outputId": "bde29254-d371-4d8d-a69d-887e4aec565f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting learn2learn\n",
            "  Downloading learn2learn-0.2.0.tar.gz (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from learn2learn) (1.26.4)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from learn2learn) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from learn2learn) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from learn2learn) (0.20.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from learn2learn) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from learn2learn) (2.32.3)\n",
            "Collecting gsutil (from learn2learn)\n",
            "  Downloading gsutil-5.33.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from learn2learn) (4.67.1)\n",
            "Collecting qpth>=0.0.15 (from learn2learn)\n",
            "  Downloading qpth-0.0.18.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.14.0->learn2learn) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.14.0->learn2learn) (0.0.8)\n",
            "Requirement already satisfied: cvxpy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qpth>=0.0.15->learn2learn) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.1.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3.0->learn2learn) (11.0.0)\n",
            "Collecting argcomplete>=3.5.1 (from gsutil->learn2learn)\n",
            "  Downloading argcomplete-3.5.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting crcmod>=1.7 (from gsutil->learn2learn)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasteners>=0.14.1 (from gsutil->learn2learn)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting gcs-oauth2-boto-plugin>=3.2 (from gsutil->learn2learn)\n",
            "  Downloading gcs-oauth2-boto-plugin-3.2.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-apitools>=0.5.32 (from gsutil->learn2learn)\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httplib2==0.20.4 (from gsutil->learn2learn)\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting google-reauth>=0.1.0 (from gsutil->learn2learn)\n",
            "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting monotonic>=1.4 (from gsutil->learn2learn)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyOpenSSL<=24.2.1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn) (24.2.1)\n",
            "Collecting retry_decorator>=1.0.0 (from gsutil->learn2learn)\n",
            "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn) (1.17.0)\n",
            "Collecting google-auth==2.17.0 (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn)\n",
            "  Downloading google_auth-2.17.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn) (0.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (4.9)\n",
            "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (3.11.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2==0.20.4->gsutil->learn2learn) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn) (2024.12.14)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn) (0.6.7.post3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn) (3.2.7)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting boto>=2.29.1 (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn)\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<5,>=3.1.4->google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (0.6.1)\n",
            "Collecting pyu2f (from google-reauth>=0.1.0->gsutil->learn2learn)\n",
            "  Downloading pyu2f-0.1.5.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn) (43.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->learn2learn) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn) (1.18.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44,>=41.0.5->pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn) (1.17.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.0->qpth>=0.0.15->learn2learn) (0.1.7.post4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL<=24.2.1,>=0.13->gsutil->learn2learn) (2.22)\n",
            "Downloading google_auth-2.17.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.1/178.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argcomplete-3.5.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: learn2learn, qpth, gsutil, crcmod, gcs-oauth2-boto-plugin, retry_decorator, pyu2f\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.2.0-cp310-cp310-linux_x86_64.whl size=1200684 sha256=9e976bce408f7a918da1e09ddf629ddb8a493e31cb1b3bbedccb62540cb26808\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/2c/13/c538cd229cdfc6c15a9d3cf64d2bb8220e205ea0f63ecb5fbe\n",
            "  Building wheel for qpth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qpth: filename=qpth-0.0.18-py3-none-any.whl size=19544 sha256=2a4eb961f80381d87a7b9e9c1c72041df0c29b16abaaee88b3247a5b714fa724\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/80/c0/2b553cc21315757f3e03846eb747795bf2a57d15bc14ef80cf\n",
            "  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsutil: filename=gsutil-5.33-py3-none-any.whl size=3789758 sha256=35299680d94f12e6ca302901d24d241ea1d921b8772422fc041bc5f01a2664f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/54/45/806bd95343bf38b37d2ba05ca45ffb0465893e93b49258f87b\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=89298a940090e8bd5149a01448ac733d61cb00dd2d2ccb1df3decba334cca5ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.2-py3-none-any.whl size=24460 sha256=4a50775cff0ffea47773551576a102da9daff7627566aecd9de3bd7cf7223a95\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/7a/33/4cc4d6af226ef2e5092b72e7a0b7bc49b42467c928dbb191d3\n",
            "  Building wheel for retry_decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retry_decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3636 sha256=6a0ae92aedf38f24fb9a229137994e8ce9ee41e3d49307fffd3892218fedbc6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/ac/77/8c54eac0d373d9eacfbe42599710c9bf91b4c5985297f6922a\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyu2f: filename=pyu2f-0.1.5-py3-none-any.whl size=39401 sha256=e761e46a147d40fa1d5f8aa0747d875438cd28013142b5084fb56373b2bd2ffe\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/7b/27/66d7389916ad9e6caabb23cb55a4cf483dbbe5e6fc2a5cb428\n",
            "Successfully built learn2learn qpth gsutil crcmod gcs-oauth2-boto-plugin retry_decorator pyu2f\n",
            "Installing collected packages: retry_decorator, monotonic, crcmod, boto, rsa, pyu2f, httplib2, fasteners, argcomplete, google-reauth, google-auth, google-apitools, gcs-oauth2-boto-plugin, qpth, gsutil, learn2learn\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.22.0\n",
            "    Uninstalling httplib2-0.22.0:\n",
            "      Successfully uninstalled httplib2-0.22.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.27.0\n",
            "    Uninstalling google-auth-2.27.0:\n",
            "      Successfully uninstalled google-auth-2.27.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-storage 2.19.0 requires google-auth<3.0dev,>=2.26.1, but you have google-auth 2.17.0 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.27.0, but you have google-auth 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argcomplete-3.5.2 boto-2.49.0 crcmod-1.7 fasteners-0.19 gcs-oauth2-boto-plugin-3.2 google-apitools-0.5.32 google-auth-2.17.0 google-reauth-0.1.1 gsutil-5.33 httplib2-0.20.4 learn2learn-0.2.0 monotonic-1.6 pyu2f-0.1.5 qpth-0.0.18 retry_decorator-1.1.1 rsa-4.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "httplib2"
                ]
              },
              "id": "019614a922bc4398aca72bd40f953160"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "vkmhV8vAnb6N",
        "outputId": "ea3b03c6-e3f4-4d0b-9610-285f9cb5bcb2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchmeta'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61442ad1e41f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0momniglot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcifar_fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchMetaDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmeta'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchmeta.datasets.helpers import omniglot,cifar_fs\n",
        "from torchmeta.utils.data import BatchMetaDataLoader\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN1DDSZMnb6N"
      },
      "outputs": [],
      "source": [
        "## Visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUH0zRW5nb6O"
      },
      "source": [
        "## 2) FOMAML\n",
        "FOMAML is less computationally expensive than MAML as it does not require second-order derivative computation. In this task you need to implement FOMAML algorithm, you may use torchmeta for assistance. Set the number of tasks to 16 and use the following CNN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cym-oJn0nb6O"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchmeta.modules import (MetaModule, MetaSequential, MetaConv2d,\n",
        "                               MetaBatchNorm2d, MetaLinear)\n",
        "\n",
        "\n",
        "def conv3x3(in_channels, out_channels, **kwargs):\n",
        "    return MetaSequential(\n",
        "        MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n",
        "        MetaBatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "class ConvolutionalNeuralNetwork(MetaModule):\n",
        "    def __init__(self, in_channels, num_classes, hidden_size=64):\n",
        "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.features = MetaSequential(\n",
        "            conv3x3(in_channels, hidden_size),\n",
        "            conv3x3(hidden_size, hidden_size),\n",
        "            conv3x3(hidden_size, hidden_size),\n",
        "            conv3x3(hidden_size, hidden_size)\n",
        "        )\n",
        "\n",
        "        self.classifier = MetaLinear(64, num_classes)\n",
        "\n",
        "    def forward(self, inputs,params=None): # load the params of the model optimized on a single task\n",
        "        features = self.features(inputs, params=self.get_subdict(params, 'features'))\n",
        "        features = features.view((features.size(0), -1))\n",
        "        logits = self.classifier(features, params=self.get_subdict(params, 'classifier'))\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISAeSA_Mnb6O"
      },
      "source": [
        "\n",
        "### A) Meta-Training\n",
        "\n",
        "The meta training consists of two parts. An inner loop which trains the base model using a the support set of a task for a number of epochs and tests it on the query set. In addition to an outer loop which updates the meta-model with the accumalated losses of the query sets based on the number of generated tasks. For simplicity, set the inner epochs to 1. Furthermore, set number of tasks to 16 and outer epochs to 100. Moreover, use an Adam optimizer with learning rate of 0.001 to update the meta-model and use the function *gradient_update_parameters* in torchmeta to update the base model parameters. Finally, during meta-training you should use the train set for training the base model and the test set for calculating the meta-loss and updating the meta-model.\n",
        "\n",
        "\n",
        "**Output**: Plot the accuracy and loss of the meta-model against the number of outer epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwquoO3Onb6O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from torchmeta.datasets.helpers import cifar_fs,omniglot\n",
        "from torchmeta.utils.data import BatchMetaDataLoader\n",
        "from torchmeta.utils.gradient_based import gradient_update_parameters\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "def train_maml(model):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AENhO91Cnb6O"
      },
      "source": [
        "### B) Meta-testing\n",
        "\n",
        "The testing protocol is to generate a random set of tasks using test set of the dataset. Then we iterate over each task, fine-tune the meta-trained model using the support set and test it on the query set. The process is repeated for each task, eventually the average results should be reported. We will use the same 5-way, 5-shot problem and also set the query set size to 15. Set the task size to 16 and repeat for 100 iterations. You can use *gradient_update_parameters* function to update model parameters also in meta-testing.\n",
        "\n",
        "**Note**: Don't forgot to initilaze the model between each task with the meta-trained parameters to avoid accumalting gradients from previous iterations.\n",
        "\n",
        "**Output** Average test accuracy on Omniglot should be above 50%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtOZMMl-nb6O"
      },
      "outputs": [],
      "source": [
        "def test_maml(model):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpjhcHqQnb6P"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    model = ConvolutionalNeuralNetwork(1, num_classes=5)\n",
        "\n",
        "    train_maml(model)\n",
        "    test_maml(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4GOwt1_nb6P"
      },
      "source": [
        "## 3) Reptile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp3zVfURnb6P"
      },
      "source": [
        "Reptile uses a different update rule. Hence, you can still rely on your inner and outer loops implemented before in the previous task, however, updating the meta-parameters should be performed by accumlating the difference between the meta-model parameters and the parameters learned on each individual task, as learned in the lecture. In this case we need to modify only the update part. Note that reptile does not require a query set to update the model parameters, unlike MAML.\n",
        "\n",
        "Update rule $$ \\theta \\leftarrow \\theta + \\frac{\\beta}{n} \\sum_{i=1}^{n}{(\\theta_{i}^\\prime - \\theta)}$$\n",
        "\n",
        "Use the same hyperparameters and optimizers as listed in FOMAML, moreover, set Beta to 1e-1.\n",
        "\n",
        "**Output** Use the same meta-testing process and report test accuracy on test set of omniglot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWl23Mbunb6P"
      },
      "outputs": [],
      "source": [
        "def train_reptile(model):\n",
        "   pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKufqB0nb6P"
      },
      "source": [
        "After training with reptile, you should perform the meta-testing process using the test set of omniglot. Similarly, set the task size to 16 and repeat for 100 iterations, fine-tune the meta-trained model using the support set and test on the query set. For fine-tuning use an Adam optimizer with learning rate 1e-3. You should notice an average test accuracy above 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOvBCLalnb6P"
      },
      "outputs": [],
      "source": [
        "def test_reptile(model):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hdcuUkDnb6P"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    model = ConvolutionalNeuralNetwork(1, num_classes=5)\n",
        "\n",
        "    train_reptile(model)\n",
        "\n",
        "    test_reptile(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvtOA3JZnb6Q"
      },
      "source": [
        "Try to repeat the same experiments with 5-way, 1-shot classification task at test time. How do the results differ ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S17b-5Vunb6Q"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}